{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Embedding, Bidirectional, RepeatVector\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\", encoding = \"utf8\") as f:\n",
    "        data = f.read().split('\\n')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "english_sentences = load_file('data/en_data')\n",
    "french_sentences = load_file('data/fr_data')\n",
    "\n",
    "print('Dataset Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris is sometimes warm during june , but it is usually hot in july .\n",
      "paris est parfois chaud en juin , mais il est généralement chaud en juillet .\n"
     ]
    }
   ],
   "source": [
    "print(english_sentences[0])\n",
    "print(french_sentences[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 1, 10, 68, 4, 46, 7, 3, 1, 9, 64, 2, 37]\n",
      "[29, 1, 9, 125, 37, 11, 46, 6, 3, 1, 12, 58, 2, 44]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(input):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(input)\n",
    "    input_tokenized = tokenizer.texts_to_sequences(input)\n",
    "    \n",
    "    return input_tokenized, tokenizer\n",
    "\n",
    "french_data_tokenized, french_tokenizer = tokenize(french_sentences)\n",
    "english_data_tokenized, english_tokenizer = tokenize(english_sentences)\n",
    "\n",
    "print(english_data_tokenized[1])\n",
    "print(french_data_tokenized[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18  1 10 68  4 46  7  3  1  9 64  2 37  0  0]\n",
      "[[ 29]\n",
      " [  1]\n",
      " [  9]\n",
      " [125]\n",
      " [ 37]\n",
      " [ 11]\n",
      " [ 46]\n",
      " [  6]\n",
      " [  3]\n",
      " [  1]\n",
      " [ 12]\n",
      " [ 58]\n",
      " [  2]\n",
      " [ 44]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]]\n"
     ]
    }
   ],
   "source": [
    "def pad(input, length=None):\n",
    "   \n",
    "    if length == None:\n",
    "        length = max([len(seq) for seq in input])\n",
    "        \n",
    "    return pad_sequences(input, maxlen=length, padding='post')\n",
    "\n",
    "\n",
    "french_data_padded = pad(french_data_tokenized)\n",
    "french_data_padded = french_data_padded.reshape(*french_data_padded.shape, 1)\n",
    "english_data_padded = pad(english_data_tokenized)\n",
    "\n",
    "print(english_data_padded[1])\n",
    "print(french_data_padded[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Build a simple RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_model(input_shape, output_len, num_uniq_fr_words):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=256, input_shape=input_shape[1:], return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(num_uniq_fr_words)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    learning_rate = 0.002\n",
    "        \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Advanced RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def advanced_model(input_shape, output_len, num_uniq_en_words, num_uniq_fr_words):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_uniq_en_words, 512, input_length=input_shape[1]))\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=False)))\n",
    "    model.add(RepeatVector(output_len))\n",
    "    model.add(Bidirectional(LSTM(512, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(num_uniq_fr_words)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    learning_rate=0.002\n",
    "    \n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/10\n",
      "110288/110288 [==============================] - 49s - loss: 2.0923 - acc: 0.5273 - val_loss: nan - val_acc: 0.6412\n",
      "Epoch 2/10\n",
      "110288/110288 [==============================] - 47s - loss: 1.0994 - acc: 0.6960 - val_loss: nan - val_acc: 0.7499\n",
      "Epoch 3/10\n",
      "110288/110288 [==============================] - 47s - loss: 0.6902 - acc: 0.7965 - val_loss: nan - val_acc: 0.8418\n",
      "Epoch 4/10\n",
      "110288/110288 [==============================] - 47s - loss: 0.3837 - acc: 0.8880 - val_loss: nan - val_acc: 0.9144\n",
      "Epoch 5/10\n",
      "110288/110288 [==============================] - 48s - loss: 0.2233 - acc: 0.9351 - val_loss: nan - val_acc: 0.9502\n",
      "Epoch 6/10\n",
      "110288/110288 [==============================] - 48s - loss: 0.1509 - acc: 0.9559 - val_loss: nan - val_acc: 0.9551\n",
      "Epoch 7/10\n",
      "110288/110288 [==============================] - 48s - loss: 0.1178 - acc: 0.9651 - val_loss: nan - val_acc: 0.9646\n",
      "Epoch 8/10\n",
      "110288/110288 [==============================] - 48s - loss: 0.0935 - acc: 0.9725 - val_loss: nan - val_acc: 0.9685\n",
      "Epoch 9/10\n",
      "110288/110288 [==============================] - 48s - loss: 0.0803 - acc: 0.9763 - val_loss: nan - val_acc: 0.9739\n",
      "Epoch 10/10\n",
      "110288/110288 [==============================] - 48s - loss: 0.0691 - acc: 0.9794 - val_loss: nan - val_acc: 0.9735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21fac003a20>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = advanced_model(english_data_padded.shape, french_data_padded.shape[1], \n",
    "                       len(english_tokenizer.word_index), len(french_tokenizer.word_index))\n",
    "model.fit(english_data_padded, french_data_padded, batch_size=1024, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chine est généralement chaud en février et il est généralement merveilleux en hiver |empty space| |empty space| |empty space| |empty space| |empty space| |empty space| |empty space| |empty space|\n"
     ]
    }
   ],
   "source": [
    "    fr_id_to_word = {value: key for key, value in french_tokenizer.word_index.items()}\n",
    "    fr_id_to_word[0] = '|empty space|'\n",
    "\n",
    "    sentence = 'china is usually hot during february and it is usually wonderful in winter'\n",
    "    sentence = [english_tokenizer.word_index[word] for word in sentence.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=english_data_padded.shape[-1], padding='post')\n",
    "\n",
    "    sentences = np.array([sentence[0]])\n",
    "    predictions = model.predict(sentence)\n",
    "\n",
    "\n",
    "    print(' '.join([fr_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
